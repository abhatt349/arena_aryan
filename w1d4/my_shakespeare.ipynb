{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "Ww0BZ9js8VLS",
        "j2ekywI3-FiU"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "09247edab3c246c1a907de3af3f50096": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c21734af2bf143fca3a5ab0f16ff03e9",
              "IPY_MODEL_71526bcd541144249781494da4ae9bc8",
              "IPY_MODEL_20048e63d06b47f3b9d38b4fa3efd7ce"
            ],
            "layout": "IPY_MODEL_769e1a7f0f444588bc29ddd3f6d8b597"
          }
        },
        "c21734af2bf143fca3a5ab0f16ff03e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ebfdb06852c14d58bdb46ef9cd22a77f",
            "placeholder": "​",
            "style": "IPY_MODEL_130f1331280846b181939ae2f72a5e33",
            "value": "epoch = 1, loss = 2.0620: 100%"
          }
        },
        "71526bcd541144249781494da4ae9bc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_906ff1c491bb4bc2bfbc0591be828ea1",
            "max": 622,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f0415ae09f1f44a0a40b7f125e0b07da",
            "value": 622
          }
        },
        "20048e63d06b47f3b9d38b4fa3efd7ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a39b6354af7545dbab041187aeb960f5",
            "placeholder": "​",
            "style": "IPY_MODEL_eba03c8ff5034f9eb32fdae96b5601da",
            "value": " 622/622 [01:43&lt;00:00,  6.15it/s]"
          }
        },
        "769e1a7f0f444588bc29ddd3f6d8b597": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ebfdb06852c14d58bdb46ef9cd22a77f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "130f1331280846b181939ae2f72a5e33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "906ff1c491bb4bc2bfbc0591be828ea1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f0415ae09f1f44a0a40b7f125e0b07da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a39b6354af7545dbab041187aeb960f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eba03c8ff5034f9eb32fdae96b5601da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "Ww0BZ9js8VLS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install einops fancy_einsum"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IwmaeYIB-yfv",
        "outputId": "76a3f99b-bb15-4cce-87d8-6592e49f66cb"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting einops\n",
            "  Downloading einops-0.6.0-py3-none-any.whl (41 kB)\n",
            "\u001b[K     |████████████████████████████████| 41 kB 509 kB/s \n",
            "\u001b[?25hCollecting fancy_einsum\n",
            "  Downloading fancy_einsum-0.0.3-py3-none-any.whl (6.2 kB)\n",
            "Installing collected packages: fancy-einsum, einops\n",
            "Successfully installed einops-0.6.0 fancy-einsum-0.0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %%\n",
        "from ast import Mult\n",
        "import matplotlib.pyplot as plt\n",
        "from regex import D\n",
        "import seaborn as sns\n",
        "import torch as t\n",
        "from torch import nn, norm, optim\n",
        "from torch import Tensor\n",
        "from torch.nn import functional\n",
        "from einops import reduce, repeat, rearrange\n",
        "import plotly.express as px\n",
        "import numpy as np\n",
        "from fancy_einsum import einsum\n",
        "from math import sqrt\n",
        "from dataclasses import dataclass\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from typing import Callable, Union, Optional\n",
        "from tqdm.notebook import tqdm_notebook\n",
        "from torch.distributions.categorical import Categorical\n",
        "from collections import OrderedDict\n",
        "import re"
      ],
      "metadata": {
        "id": "6nfbsA9F8wga"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@dataclass(frozen=True)\n",
        "class TransformerConfig:\n",
        "    '''Constants used throughout your decoder-only transformer model.'''\n",
        "\n",
        "    num_layers: int\n",
        "    num_heads: int\n",
        "    vocab_size: int\n",
        "    hidden_size: int\n",
        "    max_seq_len: int\n",
        "    dropout: float = 0.1\n",
        "    layer_norm_epsilon: float = 1e-05\n",
        "\n",
        "\n",
        "# %%\n",
        "\n",
        "\n",
        "def multihead_masked_attention(Q: t.Tensor, K: t.Tensor, V: t.Tensor, num_heads: int):\n",
        "    '''\n",
        "    Implements multihead masked attention on the matrices Q, K and V.\n",
        "\n",
        "    Q: shape (batch, seq, nheads*headsize)\n",
        "    K: shape (batch, seq, nheads*headsize)\n",
        "    V: shape (batch, seq, nheads*headsize)\n",
        "    '''\n",
        "\n",
        "    Q = rearrange(Q, 'batch seq (nheads h_size) -> batch seq nheads h_size', nheads = num_heads)\n",
        "    K = rearrange(K, 'batch seq (nheads h_size) -> batch seq nheads h_size', nheads = num_heads)\n",
        "    V = rearrange(V, 'batch seq (nheads h_size) -> batch seq nheads h_size', nheads = num_heads)\n",
        "\n",
        "    seq_len = Q.shape[1]\n",
        "    head_size = Q.shape[-1]\n",
        "\n",
        "    attention_scores = einsum('b seq_q nheads h_size, b seq_k nheads h_size -> b nheads seq_q seq_k', Q, K)\n",
        "\n",
        "    mask = t.zeros(size=(seq_len, seq_len), dtype=dtype, device=device)\n",
        "    for i in range(seq_len):\n",
        "        mask[..., i, i+1:] = -t.inf\n",
        "\n",
        "    attention_scores += mask\n",
        "    attention_probabilities = functional.softmax(attention_scores / sqrt(head_size), dim=-1) \n",
        "\n",
        "    values = einsum('b seq_k nheads h_size, b nheads seq_q seq_k -> b nheads seq_q h_size', V, attention_probabilities)\n",
        "    return rearrange(values, 'b nheads seq_q h_size -> b seq_q (nheads h_size)')\n",
        "\n",
        "# If the above is wrong, the most likely culprits are the following:\n",
        "# the ordering of nheads and h_size in the parentheses in the rearrange on the last line\n",
        "# or of nheads and h_size in the parentheses in the rearranges in the first three lines\n",
        "\n",
        "# If the above is wrong, the most likely culprits are the following:\n",
        "# the ordering of nheads and h_size in the parentheses in the rearrange on the last line\n",
        "# or of nheads and h_size in the parentheses in the rearranges in the first three lines\n",
        "\n",
        "# %%\n",
        "\n",
        "class MultiheadMaskedAttention(nn.Module):\n",
        "    W_QKV: nn.Linear\n",
        "    W_O: nn.Linear\n",
        "\n",
        "    def __init__(self, hidden_size: int, num_heads: int):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        self.num_heads = num_heads\n",
        "\n",
        "        self.W_QKV = nn.Linear(in_features=hidden_size, out_features=3*hidden_size, dtype=dtype, device=device)\n",
        "        self.W_O = nn.Linear(in_features=hidden_size, out_features=hidden_size, dtype=dtype, device=device)\n",
        "\n",
        "\n",
        "    def forward(self, x: t.Tensor) -> t.Tensor:\n",
        "        '''\n",
        "        x: shape (batch, seq, hidden_size)\n",
        "\n",
        "        Return: shape (batch, seq, hidden_size)\n",
        "        '''\n",
        "\n",
        "        hidden_size = x.shape[-1]\n",
        "\n",
        "        QKV = self.W_QKV(x)\n",
        "\n",
        "        # The below should also work instead of the following 3 lines\n",
        "        # Q, K, V = rearrange(QKV, 'b seq (three hidden_size) -> three b seq hidden_size', three=3)\n",
        "\n",
        "        Q = QKV[..., :hidden_size]\n",
        "        K = QKV[..., hidden_size:2*hidden_size]\n",
        "        V = QKV[..., 2*hidden_size:]\n",
        "\n",
        "        attention_values = multihead_masked_attention(Q, K, V, self.num_heads)\n",
        "\n",
        "        return self.W_O(attention_values)\n",
        "\n",
        "# If the above is wrong, the most likely culprits are the following: \n",
        "# Maybe the second line of __init__ shouldn't have out_features = 3 * hidden_size\n",
        "\n",
        "# %%\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "\n",
        "    def __init__(self, max_seq_len: int, embedding_dim: int):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        graph1 = t.arange(max_seq_len, dtype=dtype, device=device)\n",
        "        graph2 = 1 / 1e4 ** (t.arange(0,embedding_dim,step=2, dtype=dtype, device=device) / embedding_dim)\n",
        "\n",
        "        graph = t.outer(graph1, graph2)\n",
        "        graph = rearrange(t.cat([t.sin(graph), t.cos(graph)], dim=1), 'L (d1 d2) -> L (d2 d1)', d1=2)\n",
        "\n",
        "        self.register_buffer('PE_matrix', graph)\n",
        "\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        '''\n",
        "        x: shape (batch, seq_len, embedding_dim)\n",
        "        '''\n",
        "\n",
        "        seq_len = x.shape[1]\n",
        "        return x + self.PE_matrix[:seq_len, :] #  type: ignore\n",
        "\n",
        "\n",
        "# %%\n",
        "\n",
        "class MLP(nn.Module):\n",
        "\n",
        "    def __init__(self, config: TransformerConfig):\n",
        "\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "        self.fc1 = nn.Linear(config.hidden_size, 4*config.hidden_size, dtype=dtype, device=device)\n",
        "        self.gelu = nn.GELU()\n",
        "        self.fc2 = nn.Linear(4*config.hidden_size, config.hidden_size, dtype=dtype, device=device)\n",
        "        self.dropout = nn.Dropout(p=config.dropout)\n",
        "\n",
        "    def forward(self, x: t.Tensor) -> t.Tensor:\n",
        "        \n",
        "        x = self.gelu(self.fc1(x))\n",
        "        x = self.dropout(self.fc2(x))\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "class DecoderBlock(nn.Module):\n",
        "\n",
        "    def __init__(self, config: TransformerConfig):\n",
        "\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "        self.attention = MultiheadMaskedAttention(self.config.hidden_size, self.config.num_heads)  # type: ignore\n",
        "        self.ln1 = nn.LayerNorm(normalized_shape=config.hidden_size, eps=config.layer_norm_epsilon)\n",
        "        self.mlp = MLP(config)\n",
        "        self.ln2 = nn.LayerNorm(normalized_shape=config.hidden_size, eps=config.layer_norm_epsilon)\n",
        "\n",
        "\n",
        "    def forward(self, x: t.Tensor) -> t.Tensor:\n",
        "\n",
        "        x = self.ln1(self.attention(x)) + x\n",
        "        x = self.ln2(self.mlp(x)) + x\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "class DecoderOnlyTransformer(nn.Module):\n",
        "\n",
        "    def __init__(self, config: TransformerConfig):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        self.token_emb = nn.Embedding(num_embeddings=config.vocab_size, embedding_dim=config.hidden_size)\n",
        "        self.pos_emb = PositionalEncoding(config.max_seq_len, config.hidden_size)\n",
        "        self.dropout = nn.Dropout(p=config.dropout)\n",
        "        # self.blocks = nn.Sequential({'block '+str(i):DecoderBlock(config) for i in range(config.num_layers)}) # type: ignore\n",
        "        self.blocks = nn.Sequential(OrderedDict(\n",
        "            [(f'block {i}',DecoderBlock(config)) for i in range(config.num_layers)]\n",
        "            )) # type: ignore\n",
        "        self.layer_norm = nn.LayerNorm(normalized_shape=config.hidden_size)\n",
        "\n",
        "\n",
        "    def forward(self, x: t.Tensor) -> t.Tensor:\n",
        "      \n",
        "        if len(x.shape)==1:\n",
        "            x=x.unsqueeze(dim=0)\n",
        "            \n",
        "        embedding = self.token_emb(x.to(dtype=t.long))\n",
        "        embedding = self.pos_emb(embedding)\n",
        "        embedding = self.dropout(embedding)\n",
        "        embedding = self.blocks(embedding)\n",
        "        embedding = self.layer_norm(embedding)\n",
        "\n",
        "        logits = einsum('vocab d, batch seq d -> batch seq vocab', self.token_emb.weight, embedding)\n",
        "\n",
        "        return logits\n",
        "\n",
        "# %%\n",
        "\n",
        "class CustomTextDataset(Dataset):\n",
        "    def __init__(self, text, labels):\n",
        "        self.labels = labels\n",
        "        self.text = text\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        label = self.labels[idx]\n",
        "        text = self.text[idx]\n",
        "        sample = (text, label)\n",
        "        return sample\n",
        "\n",
        "\n",
        "def train_transformer(trainloader: DataLoader, testloader: DataLoader, epochs: int, loss_fn: Callable, config: TransformerConfig) -> list:\n",
        "    '''\n",
        "    Returns tuple of (loss_list, accuracy_list), where accuracy_list contains the fraction of accurate classifications on the test set, at the end of each epoch.\n",
        "    '''\n",
        "\n",
        "    model = DecoderOnlyTransformer(config).to(device).train()\n",
        "    optimizer = t.optim.Adam(model.parameters())\n",
        "    loss_list = []\n",
        "    accuracy_list = []\n",
        "\n",
        "    for epoch in tqdm_notebook(range(epochs)):\n",
        "\n",
        "        loss = None\n",
        "        \n",
        "        for (x, y) in tqdm_notebook(trainloader, leave=False):\n",
        "\n",
        "            x = x.to(device)\n",
        "            y = y.to(device)\n",
        "            y = rearrange(y, 'batch seq_len -> (batch seq_len)')\n",
        "\n",
        "            y_hat = model(x)\n",
        "            y_hat = rearrange(y_hat, 'batch seq_len logit -> (batch seq_len) logit')\n",
        "\n",
        "            loss = loss_fn(y_hat, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            loss_list.append(loss.item())\n",
        "        \n",
        "        for (x, y) in tqdm_notebook(testloader, leave=False):\n",
        "\n",
        "            x = x.to(device)\n",
        "            y = y.to(device)\n",
        "            y = rearrange(y, 'batch seq_len -> (batch seq_len)')\n",
        "\n",
        "\n",
        "            y_hat = model(x)\n",
        "            y_hat = rearrange(y_hat, 'batch seq_len logit -> (batch seq_len) logit')\n",
        "            preds = t.argmax(y_hat, dim=1)\n",
        "            \n",
        "            accuracy = (y == preds).to(float).mean().item()\n",
        "            accuracy_list.append(accuracy)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{epochs}, train loss is {loss:.6f}\") \n",
        "\n",
        "    print(f\"Saving model to: {MODEL_FILENAME}\")\n",
        "    t.save(model, MODEL_FILENAME)\n",
        "    return [loss_list, accuracy_list]\n",
        "\n"
      ],
      "metadata": {
        "id": "TZ1QzuaI8ZBZ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def greedy_search(logits: t.Tensor) -> int:\n",
        "    \"\"\"\n",
        "    logits: shape (vocab_size, )\n",
        "\n",
        "    Return: the most likely token (as an integer)\n",
        "    \"\"\"\n",
        "    out = logits.argmax().item()\n",
        "    assert isinstance(out, int)\n",
        "    return out\n",
        "\n",
        "def sample_basic(logits: t.Tensor) -> int:\n",
        "    \"\"\"\n",
        "    logits: shape (vocab_size, ) - unnormalized log-probabilities\n",
        "\n",
        "    Return: a sampled token\n",
        "    \"\"\"\n",
        "    distribution = t.distributions.categorical.Categorical(logits=logits)\n",
        "    out = distribution.sample().item()\n",
        "    assert isinstance(out, int)\n",
        "    return out\n",
        "\n",
        "def apply_temperature(logits: t.Tensor, temperature: float) -> t.Tensor:\n",
        "    \"\"\"\n",
        "    logits: shape (vocab_size, )\n",
        "\n",
        "    Return: shape (vocab_size, )\n",
        "    \"\"\"\n",
        "    assert temperature > 0\n",
        "    return logits / temperature\n",
        "\n",
        "def apply_freq_penalty(input_ids: t.Tensor, logits: t.Tensor, freq_penalty: float) -> t.Tensor:\n",
        "    \"\"\"\n",
        "    input_ids: shape (seq, )\n",
        "    logits: shape (vocab_size, )\n",
        "    Return: shape (vocab_size, )\n",
        "    \"\"\"\n",
        "    (vocab_size,) = logits.shape\n",
        "    id_freqs = t.bincount(input_ids, minlength=vocab_size)\n",
        "    return logits - freq_penalty * id_freqs\n",
        "\n",
        "def sample_top_k(logits: t.Tensor, top_k: int) -> int:\n",
        "    \"\"\"\n",
        "    logits: shape (vocab_size, ) - unnormalized log-probabilities\n",
        "    top_k: only consider this many of the most likely tokens for sampling\n",
        "\n",
        "    Return: a sampled token\n",
        "    \"\"\"\n",
        "    top_logits, top_idx = t.topk(logits, top_k)\n",
        "    idx = t.distributions.categorical.Categorical(logits=top_logits).sample()\n",
        "    return top_idx[idx].item()\n",
        "\n",
        "def sample_top_p(logits: t.Tensor, top_p: float, min_tokens_to_keep: int = 1) -> int:\n",
        "    \"\"\"\n",
        "    logits: shape (vocab_size, ) - unnormalized log-probabilities\n",
        "    Return: a sampled token\n",
        "    \"\"\"\n",
        "    logits_sorted, indices = logits.sort(descending=True, stable=True)\n",
        "    cumul_probs = logits_sorted.softmax(-1).cumsum(-1)\n",
        "    n_keep = t.searchsorted(cumul_probs, top_p, side=\"right\").item() + 1\n",
        "    n_keep = max(n_keep, min_tokens_to_keep)\n",
        "    keep_idx = indices[:n_keep]\n",
        "    keep_logits = logits[keep_idx]\n",
        "    sample = t.distributions.categorical.Categorical(logits=keep_logits).sample()\n",
        "    return keep_idx[sample].item()"
      ],
      "metadata": {
        "id": "xKiF-z8nFn1g"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Shakespeare"
      ],
      "metadata": {
        "id": "lK_kRlWm8qot"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Definitions"
      ],
      "metadata": {
        "id": "j2ekywI3-FiU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dtype = t.float\n",
        "device = 'cuda' if t.cuda.is_available() else 'cpu'\n",
        "\n",
        "class WordsDataset(Dataset):\n",
        "    def __init__(self, words, seq_len, sample_size):\n",
        "        \n",
        "        self.words = words\n",
        "        self.seq_len = seq_len\n",
        "        self.sample_size = sample_size\n",
        "        self.vocab_size = len(set(self.words))\n",
        "        self.max_len = len(self.words) - self.seq_len + 1\n",
        "        self.word_to_tok = {word: i for (i, word) in enumerate(set(words))}\n",
        "        self.tok_to_word = {self.word_to_tok[word]: word for word in self.word_to_tok}\n",
        "        self.tokens = t.tensor([self.word_to_tok[word] for word in self.words], dtype=dtype, device=device)\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(self.max_len * self.sample_size)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        current_seq = self.tokens[idx: idx + self.seq_len + 1]\n",
        "        x = current_seq[:-1]\n",
        "        y = current_seq[1:]\n",
        "\n",
        "        return x, y\n",
        "\n",
        "\n",
        "# %%\n",
        "\n",
        "class WordsTokenizer():\n",
        "    model_max_length: int\n",
        "\n",
        "    def __init__(self, wordsdataset: WordsDataset):\n",
        "        \n",
        "        self.word_to_tok = wordsdataset.word_to_tok\n",
        "        self.tok_to_word = wordsdataset.tok_to_word\n",
        "        self.model_max_length = wordsdataset.seq_len\n",
        "\n",
        "    def encode(self, initial_text: str, return_tensors: Optional[str] = None) -> Union[list, t.Tensor]:\n",
        "        '''\n",
        "        Tokenizes initial_text, then returns the token ids.\n",
        "\n",
        "        Return type is list by default, but if return_tensors=\"pt\" then it is returned as a tensor.\n",
        "        '''\n",
        "\n",
        "        words = re.split(r'\\b', initial_text)\n",
        "        words = [word for word in words if word]\n",
        "\n",
        "        tokens = [self.word_to_tok[word] for word in words]\n",
        "        if return_tensors == 'pt':\n",
        "            tokens = t.tensor(tokens, dtype=dtype, device=device)\n",
        "\n",
        "        return tokens\n",
        "        \n",
        "\n",
        "    def decode(self, list_of_ids: Union[t.Tensor, list]) -> str:\n",
        "        '''\n",
        "        Converts ids to a list of tokens, then joins them into a single string.\n",
        "        '''\n",
        "        \n",
        "        return ''.join([self.tok_to_word[int(token)] for token in list_of_ids])\n",
        "\n",
        "\n",
        "# %%\n",
        "\n",
        "\n",
        "def apply_sampling_methods(\n",
        "    input_ids: t.Tensor, logits: t.Tensor, temperature=1.0, freq_penalty=0.0, top_k=0, top_p=0.0\n",
        ") -> int:\n",
        "    '''\n",
        "    Return the next token, sampled from the model's probability distribution with modifiers.\n",
        "x\n",
        "    input_ids: shape (seq,)\n",
        "    '''\n",
        "    assert input_ids.ndim == 1, \"input_ids should be a 1D sequence of token ids\"\n",
        "    assert temperature >= 0, \"Temperature should be non-negative\"\n",
        "    assert 0 <= top_p <= 1.0, \"Top-p must be a probability\"\n",
        "    assert 0 <= top_k, \"Top-k must be non-negative\"\n",
        "    assert not (top_p != 0 and top_k != 0), \"At most one of top-p and top-k supported\"\n",
        "\n",
        "    if temperature == 0:\n",
        "        return greedy_search(logits)\n",
        "    if temperature != 1.0:\n",
        "        logits = apply_temperature(logits, temperature)\n",
        "    if freq_penalty != 0.0:\n",
        "        logits = apply_freq_penalty(input_ids, logits, freq_penalty)\n",
        "    if top_k > 0:\n",
        "        return sample_top_k(logits, top_k)\n",
        "    if top_p > 0:\n",
        "        return sample_top_p(logits, top_p)\n",
        "    return sample_basic(logits)\n",
        "\n",
        "\n",
        "def sample_tokens(\n",
        "    model: DecoderOnlyTransformer,\n",
        "    tokenizer: WordsTokenizer,\n",
        "    initial_text: str,\n",
        "    max_tokens_generated=30,\n",
        "    **kwargs # kwargs are for params like temperature, top_k, etc\n",
        ") -> str:\n",
        "    '''\n",
        "    Sample tokens until the model outputs `tokenizer.eos_token_id` or the specified token limit is reached.\n",
        "\n",
        "    Return: the prompt and continuation concatenated\n",
        "    '''\n",
        "    # Note - an alternative to model.eval() is to use the @t.inference_mode() decorator for this whole function.\n",
        "    model.eval()\n",
        "    input_ids: list = tokenizer.encode(initial_text) # type: ignore\n",
        "    generated = []\n",
        "    for _ in range(max_tokens_generated):\n",
        "        new_input_ids = t.tensor(input_ids + generated, dtype=t.long, device=device)\n",
        "        new_input_ids_window = new_input_ids[-min(max_seq_len, new_input_ids.shape[0]):]\n",
        "        logits = model(new_input_ids_window)[0, -1]\n",
        "        new_token = apply_sampling_methods(new_input_ids, logits, **kwargs)\n",
        "        generated.append(new_token)\n",
        "        if new_token == getattr(tokenizer, \"eos_token_id\", None):\n",
        "            break\n",
        "    return tokenizer.decode(input_ids + generated)\n"
      ],
      "metadata": {
        "id": "WJahqhvR-KRS"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "FVBVnIux-L2H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_transformer(model, loss_fn, optimizer, trainloader, epochs, plot_loss=True):\n",
        "\n",
        "    loss_list = []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        \n",
        "        progress_bar = tqdm_notebook(trainloader)\n",
        "        for (x, y) in progress_bar:\n",
        "\n",
        "            x = x.to(device=device)\n",
        "            y = y.to(dtype=t.int64, device=device)\n",
        "\n",
        "            y_hat = rearrange(model(x), \"b s d -> (b s) d\")\n",
        "            y = t.flatten(y)\n",
        "\n",
        "            loss = loss_fn(y_hat, y)\n",
        "            loss_list.append(loss.item())\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            progress_bar.set_description(f\"epoch = {epoch+1}, loss = {loss.item():.4f}\")\n",
        "\n",
        "    # Function to plot the loss over epochs\n",
        "    if plot_loss:\n",
        "        fig = px.line(\n",
        "            y=loss_list, \n",
        "            template=\"simple_white\", \n",
        "            labels={\n",
        "                \"x\": \"No. batches seen\", \n",
        "                \"y\": str(loss_fn).replace(\"()\", \"\") # This gets a name like \"CrossEntropyLoss\" from the loss function\n",
        "            }, \n",
        "            title='Training loss'\n",
        "        )\n",
        "        # This next bit of code plots vertical lines corresponding to the epochs\n",
        "        if epochs > 1:\n",
        "            for idx, epoch_start in enumerate(np.linspace(0, len(loss_list), epochs, endpoint=False)):\n",
        "                fig.add_vline(x=epoch_start, line_width=3, line_dash=\"dash\", annotation_text=f\"Epoch {idx}\", annotation_position=\"top right\")\n",
        "        fig.show()\n",
        "    \n",
        "    return model\n"
      ],
      "metadata": {
        "id": "Aw5T_5j19GCN"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_seq_len = 48\n",
        "batch_size = 32\n",
        "\n",
        "with open(\"100-0.txt\") as file:\n",
        "    text = file.read()\n",
        "    words = re.split(r\"\\b\", text)\n",
        "\n",
        "trainset = WordsDataset(words=words, seq_len=max_seq_len, sample_size=0.01)\n",
        "trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
        "tokenizer = WordsTokenizer(trainset)\n",
        "\n",
        "config = TransformerConfig(\n",
        "    num_layers = 8,\n",
        "    num_heads = 8,\n",
        "    vocab_size = trainset.vocab_size,\n",
        "    hidden_size = 512,\n",
        "    max_seq_len = trainset.seq_len,\n",
        "    dropout = 0.1,\n",
        "    layer_norm_epsilon = 1e-05\n",
        ")\n",
        "\n",
        "model = DecoderOnlyTransformer(config).to(device).train()\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "epochs = 1"
      ],
      "metadata": {
        "id": "NwXBjyRr-e4B"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = train_transformer(model, loss_fn, optimizer, trainloader, epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 574,
          "referenced_widgets": [
            "09247edab3c246c1a907de3af3f50096",
            "c21734af2bf143fca3a5ab0f16ff03e9",
            "71526bcd541144249781494da4ae9bc8",
            "20048e63d06b47f3b9d38b4fa3efd7ce",
            "769e1a7f0f444588bc29ddd3f6d8b597",
            "ebfdb06852c14d58bdb46ef9cd22a77f",
            "130f1331280846b181939ae2f72a5e33",
            "906ff1c491bb4bc2bfbc0591be828ea1",
            "f0415ae09f1f44a0a40b7f125e0b07da",
            "a39b6354af7545dbab041187aeb960f5",
            "eba03c8ff5034f9eb32fdae96b5601da"
          ]
        },
        "id": "TYnR_CGd-9Wc",
        "outputId": "c266b811-ab04-4e20-ef0e-45e40875b71c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/622 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "09247edab3c246c1a907de3af3f50096"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"9c9ae6f9-acf5-4db9-a176-2416c2dc516d\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"9c9ae6f9-acf5-4db9-a176-2416c2dc516d\")) {                    Plotly.newPlot(                        \"9c9ae6f9-acf5-4db9-a176-2416c2dc516d\",                        [{\"hovertemplate\":\"No. batches seen=%{x}<br>CrossEntropyLoss=%{y}<extra></extra>\",\"legendgroup\":\"\",\"line\":{\"color\":\"#1F77B4\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506,507,508,509,510,511,512,513,514,515,516,517,518,519,520,521,522,523,524,525,526,527,528,529,530,531,532,533,534,535,536,537,538,539,540,541,542,543,544,545,546,547,548,549,550,551,552,553,554,555,556,557,558,559,560,561,562,563,564,565,566,567,568,569,570,571,572,573,574,575,576,577,578,579,580,581,582,583,584,585,586,587,588,589,590,591,592,593,594,595,596,597,598,599,600,601,602,603,604,605,606,607,608,609,610,611,612,613,614,615,616,617,618,619,620,621],\"xaxis\":\"x\",\"y\":[123.72823333740234,124.61563110351562,75.0552749633789,64.38340759277344,46.78569412231445,60.78532791137695,52.2840576171875,50.829166412353516,51.59684753417969,45.133907318115234,37.92426681518555,42.99699020385742,40.3134651184082,35.0069694519043,38.998748779296875,36.51247024536133,32.81147003173828,32.326759338378906,33.6223258972168,32.05917739868164,31.543136596679688,30.672439575195312,29.985509872436523,29.04874610900879,28.166879653930664,27.7407169342041,27.1126651763916,26.27056121826172,26.81435203552246,25.128816604614258,25.13957405090332,24.525617599487305,25.184738159179688,23.335596084594727,22.686594009399414,23.125404357910156,21.70011329650879,21.635271072387695,21.124074935913086,21.45375633239746,20.66132926940918,19.695234298706055,19.15336799621582,18.791229248046875,18.78758430480957,19.21356773376465,18.010988235473633,17.879716873168945,17.240638732910156,17.572111129760742,17.072132110595703,17.60353660583496,16.71063995361328,15.791081428527832,16.541234970092773,15.689201354980469,15.831326484680176,14.692696571350098,14.478755950927734,15.022936820983887,13.790131568908691,13.11446475982666,15.340107917785645,12.882390022277832,13.084424018859863,12.706501960754395,13.168113708496094,12.74414348602295,12.674065589904785,12.854564666748047,11.86795425415039,12.091546058654785,11.203444480895996,12.57553768157959,11.321555137634277,10.507630348205566,10.863957405090332,11.0529203414917,10.619172096252441,9.961552619934082,11.203765869140625,9.984782218933105,9.92591381072998,9.585593223571777,9.609419822692871,11.079440116882324,9.941727638244629,9.850190162658691,9.447527885437012,8.896576881408691,9.494439125061035,8.59219741821289,8.960087776184082,8.43506908416748,8.949885368347168,8.980446815490723,9.43339729309082,8.16111946105957,8.6597261428833,9.311233520507812,8.396486282348633,8.68567943572998,8.749934196472168,7.915201187133789,8.375450134277344,8.047088623046875,7.50776481628418,7.855370998382568,8.4396390914917,7.815380573272705,8.23376750946045,7.262204647064209,7.215102672576904,7.545372009277344,7.397531986236572,6.971405506134033,7.001425266265869,6.578589916229248,7.205257892608643,6.968104839324951,7.226617336273193,6.799191951751709,6.678656101226807,6.69072151184082,6.915912628173828,6.827747821807861,6.568857192993164,6.949657917022705,6.629945755004883,6.7492499351501465,6.839091777801514,6.964639663696289,6.226180553436279,6.355601787567139,6.144859790802002,6.556928634643555,6.34721040725708,6.623340129852295,5.978649616241455,5.852535724639893,6.375302791595459,6.4413933753967285,5.790127277374268,5.804830074310303,6.4386773109436035,5.672479152679443,6.165891170501709,5.991432189941406,6.024857997894287,5.779209613800049,5.877998352050781,5.370204448699951,5.895497798919678,5.979877471923828,5.478708267211914,5.962026119232178,5.769099712371826,5.682000637054443,5.203824996948242,5.6875691413879395,5.784143447875977,5.590107440948486,5.1622395515441895,5.467275619506836,5.228796005249023,5.285766124725342,5.507938385009766,5.607943058013916,5.30304479598999,5.371448040008545,5.325372219085693,5.54218864440918,5.354104518890381,5.637159824371338,5.50349235534668,5.613483905792236,5.133245944976807,5.79327392578125,5.657144069671631,5.669360637664795,5.485151767730713,5.043179988861084,5.022904872894287,4.963188648223877,5.645721912384033,5.672243118286133,5.021464824676514,5.449693202972412,5.07340145111084,6.012256622314453,5.3958868980407715,5.281130313873291,4.949071407318115,5.373301029205322,5.055832386016846,4.809640407562256,5.020545959472656,5.055229663848877,5.309708118438721,5.018666744232178,4.8231611251831055,5.1390838623046875,4.92093563079834,5.292468070983887,5.074821472167969,5.269416809082031,4.966813087463379,4.742558002471924,4.591024398803711,4.984982013702393,4.973178386688232,4.939645290374756,4.744648456573486,4.611584186553955,4.895988941192627,4.813170909881592,4.643347263336182,4.944539546966553,5.309218883514404,4.893324851989746,4.537144184112549,4.627688884735107,4.80683708190918,4.880250453948975,4.845750331878662,4.550698757171631,4.88405179977417,4.3592987060546875,4.664915084838867,4.505821704864502,4.360945701599121,4.605618476867676,4.470860004425049,4.631846904754639,4.496505260467529,4.607640266418457,4.316556453704834,4.3491010665893555,4.260426998138428,4.352113723754883,4.588250637054443,4.8039631843566895,4.410942554473877,4.4341607093811035,4.292644023895264,4.451389789581299,4.454172611236572,4.44517183303833,4.5200886726379395,4.1935014724731445,4.2227864265441895,4.277194499969482,4.453445911407471,4.45418119430542,4.372208118438721,4.33357572555542,4.418263912200928,4.318458080291748,4.131129264831543,4.3152899742126465,4.443586826324463,4.2558913230896,4.253641128540039,4.271481513977051,4.479280471801758,4.2020487785339355,4.24286413192749,4.225088119506836,4.247743606567383,4.031741142272949,4.1414875984191895,4.387528419494629,4.116855144500732,4.092951774597168,4.279147624969482,4.234152793884277,4.041288375854492,4.02229118347168,4.152850151062012,4.24544095993042,4.046383380889893,4.134217739105225,4.21388053894043,4.083939552307129,4.007901668548584,4.063331127166748,3.996846914291382,4.1408514976501465,4.182525634765625,4.051252841949463,3.994981527328491,4.12797212600708,4.147711277008057,4.055216312408447,3.9797468185424805,3.987347364425659,4.023969650268555,4.264454364776611,4.082809925079346,4.024125576019287,4.120431900024414,4.248557090759277,4.165706157684326,3.7544639110565186,3.824187994003296,3.993544816970825,4.125849723815918,4.245025157928467,4.162302017211914,4.017237186431885,4.13617467880249,4.026613712310791,3.8648130893707275,4.006533622741699,3.986186981201172,3.979296922683716,3.771517753601074,3.987262487411499,4.047026634216309,3.8641250133514404,3.8969802856445312,3.9578800201416016,4.086772918701172,3.9632961750030518,3.9411556720733643,3.9729936122894287,3.867940664291382,4.003549098968506,3.848689079284668,3.7215893268585205,4.021866798400879,4.084434986114502,3.759251356124878,4.013035297393799,3.7367970943450928,3.8189733028411865,3.8716888427734375,3.7986385822296143,3.7146289348602295,3.866705894470215,3.8088901042938232,3.851656198501587,3.8905391693115234,3.8320844173431396,3.762321710586548,3.839487314224243,3.84085750579834,3.9579102993011475,3.8957138061523438,3.778287887573242,3.7234458923339844,3.715522527694702,3.6877081394195557,4.059672832489014,3.6763429641723633,3.567967176437378,3.7573611736297607,3.685234785079956,3.7796478271484375,3.6515614986419678,3.618332862854004,3.583073377609253,3.7928988933563232,3.8606770038604736,3.706131935119629,3.6955506801605225,3.805363893508911,3.707504987716675,3.751415252685547,3.75069522857666,3.6544277667999268,3.7347917556762695,3.922067880630493,3.8085591793060303,3.780465841293335,3.6135504245758057,3.6453821659088135,3.590054750442505,3.603973627090454,3.735088586807251,3.607353448867798,3.6544973850250244,3.608085870742798,3.728618621826172,3.549241065979004,3.64986515045166,3.7407617568969727,3.679203748703003,3.654240846633911,3.762829065322876,3.547136068344116,3.6642322540283203,3.7333028316497803,3.6633169651031494,3.77919602394104,3.790992021560669,3.394238233566284,3.606349229812622,3.5024101734161377,3.627864122390747,3.480604887008667,3.3818063735961914,3.5209805965423584,3.6400296688079834,3.488872766494751,3.476883888244629,3.465751886367798,3.535646438598633,3.4701812267303467,3.248460531234741,3.5437259674072266,3.3233633041381836,3.535921096801758,3.434906244277954,3.4862844944000244,3.3299567699432373,3.473278284072876,3.288179397583008,3.4920270442962646,3.595829725265503,3.35326886177063,3.5437803268432617,3.408419370651245,3.340006113052368,3.2202413082122803,3.303582191467285,3.3690860271453857,3.365690231323242,3.3568365573883057,3.3641016483306885,3.1597213745117188,3.396862268447876,3.2469542026519775,3.296008825302124,3.3006508350372314,3.261944055557251,3.331474542617798,3.348895788192749,3.1365139484405518,3.2460038661956787,3.308852195739746,3.101045608520508,3.3809831142425537,3.0667543411254883,3.186777353286743,3.2047739028930664,3.1359128952026367,3.120239496231079,3.0682179927825928,3.2832224369049072,3.140170097351074,3.275799036026001,3.2071285247802734,3.023838996887207,3.2150399684906006,3.078092575073242,3.3117916584014893,3.1865317821502686,3.1425154209136963,3.170990228652954,3.118074655532837,3.03473162651062,3.2105720043182373,2.9729526042938232,3.072138547897339,3.1741456985473633,2.937622308731079,2.9787042140960693,3.2734758853912354,3.07442307472229,3.1565780639648438,3.01125431060791,2.946971893310547,2.8656749725341797,3.130600929260254,3.058833360671997,2.999915838241577,3.0565097332000732,3.012479782104492,2.945570945739746,2.819249391555786,3.083256483078003,2.9626381397247314,2.9053561687469482,2.925290107727051,2.929844617843628,2.7816002368927,2.902867317199707,2.948019027709961,2.968214988708496,3.0087268352508545,2.972097158432007,2.799197196960449,2.8153841495513916,2.860412836074829,2.8961803913116455,2.924896001815796,2.806674003601074,2.6715614795684814,2.952622413635254,2.8697612285614014,2.826181411743164,2.710319757461548,2.708489179611206,2.7283098697662354,2.7194225788116455,2.747382164001465,2.6813533306121826,2.8160791397094727,2.614558458328247,2.5820248126983643,2.9079768657684326,2.8179080486297607,2.682506561279297,2.68279767036438,2.695606231689453,2.7687695026397705,2.6638150215148926,2.77010440826416,2.7564048767089844,2.535681962966919,2.568608522415161,2.568624258041382,2.66251540184021,2.6293652057647705,2.584791898727417,2.441054582595825,2.6082069873809814,2.359192132949829,2.5433156490325928,2.487316846847534,2.452956438064575,2.6365835666656494,2.4317147731781006,2.4210798740386963,2.4985475540161133,2.669168472290039,2.6115729808807373,2.279052972793579,2.3692243099212646,2.529937267303467,2.4160988330841064,2.4469244480133057,2.348484992980957,2.2970356941223145,2.3767850399017334,2.4389233589172363,2.423177480697632,2.4110896587371826,2.3860864639282227,2.471374750137329,2.3237216472625732,2.3964498043060303,2.392214059829712,2.251127004623413,2.3167238235473633,2.399897813796997,2.209074020385742,2.2741470336914062,2.2635819911956787,2.2761149406433105,2.2861032485961914,2.304682970046997,2.3356592655181885,2.4474246501922607,2.263575792312622,2.3169593811035156,2.213740110397339,2.1548898220062256,2.221784830093384,2.1444029808044434,2.2231554985046387,2.136002540588379,2.2454323768615723,1.9991456270217896,2.12038516998291,2.0167176723480225,2.220036745071411,2.050081729888916,2.19109845161438,2.2164862155914307,2.1446261405944824,2.1716482639312744,2.241992473602295,2.1575067043304443,2.0349886417388916,2.156047821044922,1.9321810007095337,1.9672666788101196,2.2686479091644287,2.016279935836792,2.090148687362671,1.9947381019592285,2.187310218811035,1.9735227823257446,1.9828203916549683,2.073885679244995,1.8983521461486816,1.9086819887161255,1.9243663549423218,1.960963249206543,1.816591739654541,1.8252469301223755,1.9016308784484863,1.8790448904037476,1.9157711267471313,1.8951772451400757,2.015425443649292,1.81501042842865,2.0186233520507812,1.9017291069030762,1.8179415464401245,1.9483884572982788,1.8395742177963257,1.7510093450546265,1.918323040008545,1.8041495084762573,2.0300629138946533,1.5782140493392944,1.8758665323257446,1.7969969511032104,2.062020778656006],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"rgb(36,36,36)\"},\"error_y\":{\"color\":\"rgb(36,36,36)\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"rgb(36,36,36)\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"rgb(36,36,36)\"},\"baxis\":{\"endlinecolor\":\"rgb(36,36,36)\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"rgb(36,36,36)\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.6}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"rgb(237,237,237)\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"rgb(217,217,217)\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"colorscale\":{\"diverging\":[[0.0,\"rgb(103,0,31)\"],[0.1,\"rgb(178,24,43)\"],[0.2,\"rgb(214,96,77)\"],[0.3,\"rgb(244,165,130)\"],[0.4,\"rgb(253,219,199)\"],[0.5,\"rgb(247,247,247)\"],[0.6,\"rgb(209,229,240)\"],[0.7,\"rgb(146,197,222)\"],[0.8,\"rgb(67,147,195)\"],[0.9,\"rgb(33,102,172)\"],[1.0,\"rgb(5,48,97)\"]],\"sequential\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"sequentialminus\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]]},\"colorway\":[\"#1F77B4\",\"#FF7F0E\",\"#2CA02C\",\"#D62728\",\"#9467BD\",\"#8C564B\",\"#E377C2\",\"#7F7F7F\",\"#BCBD22\",\"#17BECF\"],\"font\":{\"color\":\"rgb(36,36,36)\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"rgb(232,232,232)\",\"gridwidth\":2,\"linecolor\":\"rgb(36,36,36)\",\"showbackground\":true,\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\",\"zeroline\":false,\"zerolinecolor\":\"rgb(36,36,36)\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"rgb(232,232,232)\",\"gridwidth\":2,\"linecolor\":\"rgb(36,36,36)\",\"showbackground\":true,\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\",\"zeroline\":false,\"zerolinecolor\":\"rgb(36,36,36)\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"rgb(232,232,232)\",\"gridwidth\":2,\"linecolor\":\"rgb(36,36,36)\",\"showbackground\":true,\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\",\"zeroline\":false,\"zerolinecolor\":\"rgb(36,36,36)\"}},\"shapedefaults\":{\"fillcolor\":\"black\",\"line\":{\"width\":0},\"opacity\":0.3},\"ternary\":{\"aaxis\":{\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\"},\"baxis\":{\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\",\"title\":{\"standoff\":15},\"zeroline\":false,\"zerolinecolor\":\"rgb(36,36,36)\"},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\",\"title\":{\"standoff\":15},\"zeroline\":false,\"zerolinecolor\":\"rgb(36,36,36)\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"No. batches seen\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"CrossEntropyLoss\"}},\"legend\":{\"tracegroupgap\":0},\"title\":{\"text\":\"Training loss\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('9c9ae6f9-acf5-4db9-a176-2416c2dc516d');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "initial_text = \"twas\"\n",
        "text_output = sample_tokens(model, tokenizer, initial_text, max_tokens_generated=100, temperature=1.0, top_k=10)\n",
        "print(text_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ECUTEiz_E-ha",
        "outputId": "452fa4f1-2fbc-4b94-8e6f-08c6f7dcad4d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "twas of and care,\n",
            "  When I was the must see, and left what all see.\n",
            "\n",
            "\n",
            "                    53\n",
            "\n",
            "Mine be have plea thee for love, shallowest is too words thyself thy it self-killed:\n",
            "That is thy use not is is change is is the tillage of thy of husbandry?\n",
            "Or survive who\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "initial_text = \"prithee\"\n",
        "text_output = sample_tokens(model, tokenizer, initial_text, max_tokens_generated=100, temperature=1.0, top_k=10)\n",
        "print(text_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0adc03b5-9dbb-4a82-c9ca-849ffd0b103a",
        "id": "71A7t2ypMCHi"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "prithee fair of the your year,\n",
            "The mayst world some toiled:\n",
            "  Then bankrupt and is praise is beauteous and thee thy dial’s use it it not their tomb\n",
            "Of his stain of through Gutenberg moan.\n",
            "  This all is one,\n",
            "  Sweet thy love love flattery, then she loves love is as\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "initial_text = \"verily\"\n",
        "text_output = sample_tokens(model, tokenizer, initial_text, max_tokens_generated=100, temperature=1.0, top_k=10)\n",
        "print(text_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98124b56-02b0-4211-b980-cc0182587ace",
        "id": "W-7YtFk-MCyx"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "verily thoughts would be although die,\n",
            "The children’s blood fair words which use,\n",
            "Possessing fair fair the of check,\n",
            "From his low death, before?\n",
            "No bosom’s the conquest of KING moan,\n",
            "Mine eye blood is to through the ere time distilled:\n",
            "Make though provoke him on him him the\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_WYbKaZpF3Fx"
      },
      "execution_count": 16,
      "outputs": []
    }
  ]
}